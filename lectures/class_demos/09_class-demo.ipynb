{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e316b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(\"..\"), \"code\"))\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from plotting_functions import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, classification_report, f1_score, precision_recall_curve, roc_auc_score, roc_curve, ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f009286",
   "metadata": {},
   "source": [
    "# Exploring classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e53c3",
   "metadata": {},
   "source": [
    "### Dataset for demonstration \n",
    "\n",
    "Let's classify fraudulent and non-fraudulent transactions using Kaggle's [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud) data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c9f03",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175ada15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64454</th>\n",
       "      <td>51150.0</td>\n",
       "      <td>-3.538816</td>\n",
       "      <td>3.481893</td>\n",
       "      <td>-1.827130</td>\n",
       "      <td>-0.573050</td>\n",
       "      <td>2.644106</td>\n",
       "      <td>-0.340988</td>\n",
       "      <td>2.102135</td>\n",
       "      <td>-2.939006</td>\n",
       "      <td>2.578654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530978</td>\n",
       "      <td>-0.860677</td>\n",
       "      <td>-0.201810</td>\n",
       "      <td>-1.719747</td>\n",
       "      <td>0.729143</td>\n",
       "      <td>-0.547993</td>\n",
       "      <td>-0.023636</td>\n",
       "      <td>-0.454966</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37906</th>\n",
       "      <td>39163.0</td>\n",
       "      <td>-0.363913</td>\n",
       "      <td>0.853399</td>\n",
       "      <td>1.648195</td>\n",
       "      <td>1.118934</td>\n",
       "      <td>0.100882</td>\n",
       "      <td>0.423852</td>\n",
       "      <td>0.472790</td>\n",
       "      <td>-0.972440</td>\n",
       "      <td>0.033833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687055</td>\n",
       "      <td>-0.094586</td>\n",
       "      <td>0.121531</td>\n",
       "      <td>0.146830</td>\n",
       "      <td>-0.944092</td>\n",
       "      <td>-0.558564</td>\n",
       "      <td>-0.186814</td>\n",
       "      <td>-0.257103</td>\n",
       "      <td>18.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79378</th>\n",
       "      <td>57994.0</td>\n",
       "      <td>1.193021</td>\n",
       "      <td>-0.136714</td>\n",
       "      <td>0.622612</td>\n",
       "      <td>0.780864</td>\n",
       "      <td>-0.823511</td>\n",
       "      <td>-0.706444</td>\n",
       "      <td>-0.206073</td>\n",
       "      <td>-0.016918</td>\n",
       "      <td>0.781531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310405</td>\n",
       "      <td>-0.842028</td>\n",
       "      <td>0.085477</td>\n",
       "      <td>0.366005</td>\n",
       "      <td>0.254443</td>\n",
       "      <td>0.290002</td>\n",
       "      <td>-0.036764</td>\n",
       "      <td>0.015039</td>\n",
       "      <td>23.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245686</th>\n",
       "      <td>152859.0</td>\n",
       "      <td>1.604032</td>\n",
       "      <td>-0.808208</td>\n",
       "      <td>-1.594982</td>\n",
       "      <td>0.200475</td>\n",
       "      <td>0.502985</td>\n",
       "      <td>0.832370</td>\n",
       "      <td>-0.034071</td>\n",
       "      <td>0.234040</td>\n",
       "      <td>0.550616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519029</td>\n",
       "      <td>1.429217</td>\n",
       "      <td>-0.139322</td>\n",
       "      <td>-1.293663</td>\n",
       "      <td>0.037785</td>\n",
       "      <td>0.061206</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>-0.057296</td>\n",
       "      <td>156.52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60943</th>\n",
       "      <td>49575.0</td>\n",
       "      <td>-2.669614</td>\n",
       "      <td>-2.734385</td>\n",
       "      <td>0.662450</td>\n",
       "      <td>-0.059077</td>\n",
       "      <td>3.346850</td>\n",
       "      <td>-2.549682</td>\n",
       "      <td>-1.430571</td>\n",
       "      <td>-0.118450</td>\n",
       "      <td>0.469383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228329</td>\n",
       "      <td>-0.370643</td>\n",
       "      <td>-0.211544</td>\n",
       "      <td>-0.300837</td>\n",
       "      <td>-1.174590</td>\n",
       "      <td>0.573818</td>\n",
       "      <td>0.388023</td>\n",
       "      <td>0.161782</td>\n",
       "      <td>57.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "64454    51150.0 -3.538816  3.481893 -1.827130 -0.573050  2.644106 -0.340988   \n",
       "37906    39163.0 -0.363913  0.853399  1.648195  1.118934  0.100882  0.423852   \n",
       "79378    57994.0  1.193021 -0.136714  0.622612  0.780864 -0.823511 -0.706444   \n",
       "245686  152859.0  1.604032 -0.808208 -1.594982  0.200475  0.502985  0.832370   \n",
       "60943    49575.0 -2.669614 -2.734385  0.662450 -0.059077  3.346850 -2.549682   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "64454   2.102135 -2.939006  2.578654  ...  0.530978 -0.860677 -0.201810   \n",
       "37906   0.472790 -0.972440  0.033833  ...  0.687055 -0.094586  0.121531   \n",
       "79378  -0.206073 -0.016918  0.781531  ... -0.310405 -0.842028  0.085477   \n",
       "245686 -0.034071  0.234040  0.550616  ...  0.519029  1.429217 -0.139322   \n",
       "60943  -1.430571 -0.118450  0.469383  ... -0.228329 -0.370643 -0.211544   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "64454  -1.719747  0.729143 -0.547993 -0.023636 -0.454966    1.00      0  \n",
       "37906   0.146830 -0.944092 -0.558564 -0.186814 -0.257103   18.49      0  \n",
       "79378   0.366005  0.254443  0.290002 -0.036764  0.015039   23.74      0  \n",
       "245686 -1.293663  0.037785  0.061206  0.005387 -0.057296  156.52      0  \n",
       "60943  -0.300837 -1.174590  0.573818  0.388023  0.161782   57.50      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_df = pd.read_csv(\"../data/creditcard.csv\", encoding=\"latin-1\")\n",
    "train_df, test_df = train_test_split(cc_df, test_size=0.3, random_state=111)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f5308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_big, y_train_big = train_df.drop(columns=[\"Class\", \"Time\"]), train_df[\"Class\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"Class\", \"Time\"]), test_df[\"Class\"]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_big, y_train_big, test_size=0.6, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56208d5e",
   "metadata": {},
   "source": [
    "## Comparing PR curves\n",
    "\n",
    "Let's create PR curves for SVC and Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6c34625",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression(max_iter = 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a76afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()), ('svc', SVC())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_svc = make_pipeline(StandardScaler(), SVC())\n",
    "pipe_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e1b2c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/celine/Documents/23fall/CPSC_330/cpsc330-2023W1/lectures/class_demos/09_class-demo.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/celine/Documents/23fall/CPSC_330/cpsc330-2023W1/lectures/class_demos/09_class-demo.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipe_lr\u001b[39m.\u001b[39;49mpredict_proba(X_valid)\n",
      "File \u001b[0;32m~/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/pipeline.py:577\u001b[0m, in \u001b[0;36mPipeline.predict_proba\u001b[0;34m(self, X, **predict_proba_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    576\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 577\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict_proba(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_proba_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1001\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, copy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    987\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \n\u001b[1;32m    989\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[39m        Transformed array.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1001\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1003\u001b[0m     copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m   1004\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1005\u001b[0m         X,\n\u001b[1;32m   1006\u001b[0m         reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1011\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/utils/validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not an estimator instance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (estimator))\n\u001b[1;32m   1461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1462\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "pipe_lr.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677529c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'y_true'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/celine/Documents/23fall/CPSC_330/cpsc330-2023W1/lectures/class_demos/09_class-demo.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/celine/Documents/23fall/CPSC_330/cpsc330-2023W1/lectures/class_demos/09_class-demo.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m precision_lr, recall_lr, thresholds_lr \u001b[39m=\u001b[39m precision_recall_curve ()\n",
      "File \u001b[0;32m~/anaconda3/envs/cpsc330/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m params \u001b[39m=\u001b[39m func_sig\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    190\u001b[0m params\u001b[39m.\u001b[39mapply_defaults()\n\u001b[1;32m    192\u001b[0m \u001b[39m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cpsc330/lib/python3.10/inspect.py:3177\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   3173\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[39m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3175\u001b[0m \u001b[39m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3176\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bind(args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cpsc330/lib/python3.10/inspect.py:3092\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3090\u001b[0m                 msg \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmissing a required argument: \u001b[39m\u001b[39m{arg!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m   3091\u001b[0m                 msg \u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mformat(arg\u001b[39m=\u001b[39mparam\u001b[39m.\u001b[39mname)\n\u001b[0;32m-> 3092\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3093\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3094\u001b[0m     \u001b[39m# We have a positional argument to process\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: missing a required argument: 'y_true'"
     ]
    }
   ],
   "source": [
    "precision_lr, recall_lr, thresholds_lr = precision_recall_curve (\n",
    "    y_train, pipe_lr.predict_proba\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8824998",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d83c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision_svc, recall_svc, thresholds_svc = precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(precision_svc, recall_svc, label=\"SVC\")\n",
    "plt.plot(precision_lr, recall_lr, label=\"Logistic regression\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092e25ca",
   "metadata": {},
   "source": [
    "### Let's look at the F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddff655",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_f1 = None\n",
    "svc_f1 = None\n",
    "\n",
    "print(lr_f1, svc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff6bbd",
   "metadata": {},
   "source": [
    "### What about the average precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ap = None\n",
    "svc_ap = None\n",
    "\n",
    "print(lr_ap, svc_ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c0dea",
   "metadata": {},
   "source": [
    "## Comparing ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab105de",
   "metadata": {},
   "source": [
    "Let's look at the ROC curve for Logistic Regression first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825ea26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "886bcbb1",
   "metadata": {},
   "source": [
    "But what if we want to plot more than one classifier? Let's look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay.from_estimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224dfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "117fe572",
   "metadata": {},
   "source": [
    "## Comparing class_weight\n",
    "\n",
    "Let's explore how the `class_weight` argument impacts performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f957b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard LogisticRegression\n",
    "pipe_lr_std = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving a weight of 1 to the non-fraud and 10 to fraud examples\n",
    "pipe_lr_upw ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68febcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced weights\n",
    "pipe_lr_balanced ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deef9b1",
   "metadata": {},
   "source": [
    "First let's look at the precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88aff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7c38fa0",
   "metadata": {},
   "source": [
    "Now let's consider the ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cc1ac51",
   "metadata": {},
   "source": [
    "# ML fairness activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84d6ef",
   "metadata": {},
   "source": [
    "AI/ML systems can give the illusion of objectivity as they are derived from seemingly unbiased data & algorithm. However, human are inherently biased and AI/ML systems, if not carefully evaluated, can even further amplify the existing inequities and systemic bias in our society.  \n",
    "\n",
    "How do we make sure our AI/ML systems are *fair*? Which metrics can we use to quatify 'fairness' in AI/ML systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b6c52",
   "metadata": {},
   "source": [
    "### Dataset for demonstration \n",
    "\n",
    "Let's examine this on [the adult census data set](https://www.kaggle.com/uciml/adult-census-income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ebaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_df = pd.read_csv(\"../data/adult.csv\")\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(census_df, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5989357",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nan = train_df.replace(\"?\", np.nan)\n",
    "test_df_nan = test_df.replace(\"?\", np.nan)\n",
    "train_df_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c44140",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\",\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"workclass\",\n",
    "    \"marital.status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"native.country\",\n",
    "]\n",
    "\n",
    "ordinal_features = [\"education\"]\n",
    "binary_features = [\n",
    "    \"sex\"\n",
    "]  # Not binary in general but in this particular dataset it seems to have only two possible values\n",
    "drop_features = [\"education.num\", \"fnlwgt\"]\n",
    "target = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"education\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_levels = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Prof-school\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Some-college\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Doctorate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a80052",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(education_levels) == set(train_df[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(columns=[target])\n",
    "y_train = train_df_nan[target]\n",
    "\n",
    "X_test = test_df_nan.drop(columns=[target])\n",
    "y_test = test_df_nan[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4905455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "ordinal_transformer = OrdinalEncoder(categories=[education_levels], dtype=int)\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(drop=\"if_binary\", dtype=int),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3066fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c818d",
   "metadata": {},
   "source": [
    "Let's build our classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca55924",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721814c",
   "metadata": {},
   "source": [
    "And look at the confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c2aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5017ab07",
   "metadata": {},
   "source": [
    "Let's examine confusion matrix separately for the two genders we have in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc = preprocessor.fit_transform(X_train)\n",
    "preprocessor.named_transformers_[\"pipeline-2\"][\"onehotencoder\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d17b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_female = X_test.query(\"sex=='Female'\")  # X where sex is female\n",
    "X_male = X_test.query(\"sex=='Male'\")  # X where sex is male\n",
    "\n",
    "y_female = y_test[X_female.index]  # y where sex is female\n",
    "y_male = y_test[X_male.index]  # y where sex is male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c407bb57",
   "metadata": {},
   "source": [
    "**Get predictions for `X_female` and `y_male` with `pipe_lr`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_preds = pipe_lr.predict(X_female)\n",
    "male_preds = pipe_lr.predict(X_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5cc0c",
   "metadata": {},
   "source": [
    "Let's examine the accuracy and confusion matrix for female class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_female, female_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae317d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(pipe_lr, X_female, y_female, normalize=\"true\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7c209",
   "metadata": {},
   "source": [
    "Let's examine the accuracy and confusion matrix for male class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_male, male_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(pipe_lr, X_male, y_male, normalize=\"true\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746017d",
   "metadata": {},
   "source": [
    "### ❓❓ Questions for group discussion\n",
    "\n",
    "Let's assume that a company is using this classifier for loan approval with a simple rule that if the income is >=50K, approve the loan else reject the loan. \n",
    "\n",
    "In your group, discuss the questions below and write the main points from your discussion in this [Google document](https://docs.google.com/document/d/1nsOsdO-zRwvWWwM4-6h2t7eHgIhW8FCy3ebxoT7p0HY/edit?usp=sharing). \n",
    "\n",
    "1. Which group has a higher accuracy?\n",
    "2. Which group has a higher precision for class >50K? What about recall for class >50K?\n",
    "3. Will both groups have more or less the same proportion of people with approved loans? \n",
    "4. If a male and a female have both a certain level of income, will they have the same chance of getting the loan?\n",
    "5. Banks want to avoid approving unqualified applications (false positives) because default loan could have detrimental effects for them. Compare the false positive rates for the two groups.    \n",
    "6. Overall, do you think this income classifier will fairly treat both groups? What will be the consequences of using this classifier in loan approval application? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b6fa7",
   "metadata": {},
   "source": [
    "**Time permitting**\n",
    "1. Do you think the effect will still exist if the sex feature is removed from the model (but you still have it available separately to do the two confusion matrices)? \n",
    "2. Are there any other groups in this dataset worth examining for biases? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
